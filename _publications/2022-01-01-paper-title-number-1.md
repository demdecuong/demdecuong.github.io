---
title: "ViHealthBERT: Pre-trained Language Models for Vietnamese in Health Text Mining"
collection: publications
permalink: /publication/2022-01-01-paper-title-number-1
excerpt: 'This paper is about building a language models for Vietnamese in Healthcare domain'
date: 2022-01-01
venue: 'LREC 2022'
paperurl: 'https://github.com/demdecuong/vihealthbert'
# citation: 'Your Name, You. (2015). &quot;Paper Title Number 3.&quot; <i>Journal 1</i>. 1(3).'
---
ViHealthBERT is a strong baseline language models for Vietnamese in Healthcare domain.

- We empirically investigate our model with different training strategies, achieving state of the art (SOTA) performances on 3 downstream tasks: NER (COVID-19 & ViMQ), Acronym Disambiguation, and Summarization.

- We introduce two Vietnamese datasets: the acronym dataset (acrDrAid) and the FAQ summarization dataset in the healthcare domain. Our acrDrAid dataset is annotated with 135 sets of keywords.

[repo](https://github.com/demdecuong/vihealthbert)
